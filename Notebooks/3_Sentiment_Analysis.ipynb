{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "o0K7C5LK9By3"
      },
      "source": [
        "## **Sentiment Analysis**\n",
        "\n",
        "In this notebook, we essentially focus on the Sentiment Analysis performance metric (more about this on the readme.md file)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NSvuyW77AZ5_"
      },
      "source": [
        "### **Steps to run this Notebook:**\n",
        "\n",
        "- **Step 1:** Download the libraries & Load the data\n",
        "- **Step 2:** Prompt the text generative LLM - using the prompt given below\n",
        "- **Step 3:** Computing and calculating the scores & download results\n",
        "- **Step 4:** Compress all in 1 function"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "giRw_CTWAhhM"
      },
      "source": [
        "### **Step 1:** Download the libraries & Load the data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "134oa12s934-"
      },
      "outputs": [],
      "source": [
        "# Keep to generate other reviews/labels in the future\n",
        "# !pip install datasets"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "08TJN7Vu-Sav"
      },
      "outputs": [],
      "source": [
        "# Import Libraries\n",
        "import pandas as pd\n",
        "from datasets import load_dataset\n",
        "import random"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "wQdy5bDR-WFq"
      },
      "outputs": [],
      "source": [
        "# Load the IMDb dataset from Hugging Face datasets\n",
        "# dataset = load_dataset(\"imdb\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "kvOUYnK389LC"
      },
      "outputs": [],
      "source": [
        "# Select a subset of reviews and their labels\n",
        "# random_indices = random.sample(range(len(dataset['train'])), 10)\n",
        "# random_reviews = [dataset['train'][i]['text'] for i in random_indices]\n",
        "# random_labels = [dataset['train'][i]['label'] for i in random_indices]\n",
        "\n",
        "# Convert label indices to actual labels\n",
        "# label_mapping = {\n",
        "#     0: 'Negative',\n",
        "#     1: 'Positive',\n",
        "#    2: 'Neutral'\n",
        "# }\n",
        "# random_labels = [label_mapping[label] for label in random_labels]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "-pUCcYFh-YZ_"
      },
      "outputs": [],
      "source": [
        "# df = pd.DataFrame({'Review': random_reviews, 'Ground_Truth_Label': random_labels})\n",
        "# df.to_csv(\"dataset_sample_movie_reviews.csv\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "7uEtOyygscxy"
      },
      "outputs": [],
      "source": [
        "df = pd.read_csv(\"./content/dataset_sample_movie_reviews_v2.csv\") # delete . if on colab"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ChcVaYLg-hZ1",
        "outputId": "991c6100-bc04-44ce-a8ac-ab12964cd972"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "['Just got through watching this version of \"Samhain\", and even though I still like it, it\\'s nothing like the \"rough cut\" version I have. If you check the message board, you\\'ll see an apology from the director for this cut down version, 79 minutes., and he says he had nothing to do with this R-rated trimmed down edit with a completely new screwed up ending. Christian really doesn\\'t need to distant himself that much, because the basic gore elements still stand up, even though highly trimmed down. This is a damn shame, because this had the potential of being one of the goriest and best gore films in years. It still has the porn stars, and the inbreds, and some of the extreme gore can at least be partially seen. I\\'m just glad I have that \"rough cut\", because to me, it\\'s a jewel for any gorehounds library. Christian Viel definitely has the skill and vision to deliver the goods, and hopefully his next project will be better produced. The idiots had a near classic in their hands, and screwed it up for everybody. \"Samhain\" may be one of the most controversial and mishandled horror movies ever, and too bad gorehounds didn\\'t get to see what the director intended.<br /><br />********************************************* Just so you know what you missed, this is my review based upon the \"work print\" of SAMHAIN.<br /><br />The movie runs a little over 90 minutes and has no chapter stops. There is absolutely NO music soundtrack, and some of the scenes have no audio on the dialog, because I think they are meant to be looped in later. However, most of the movie does have audio with sound affects, and when an effect or scene is missing, a message appears as a cue for insertion when the movie is completed. It\\'s exactly as it says, a \"Rough Cut\", BUT the only uncut version of \"Samhain\" you are ever likely to see. Reason, because the gore is extremely graphic, much more than even an NC-17 would allow. Yes there are a few porn stars, but they are just there for the killing, and to add a little sugar and spice. The story is pretty standard, American tourists on a vacation in Ireland and end up staying in a home in the middle of the woods. An area that is heavy on folklore, involving the ancient Druids and the celebration of Samhain, or as we call it Halloween. (spooky)<br /><br />The movie starts off with a HUGE dose of gore, as a camping couple is attacked by one of the local inbred mutants. This is a great gore scene, as the guy find his girl hanging from a cliff, with her crying for help. All he sees is her head, arms, and shoulders hanging in front of him and when he pulls her up, she has been completely sliced in two. This is what I would call EXTREME GORE, with entrails, blood, and severed limbs all over the place. We are in Herschell Gordon Lewis territory here folks, except the effects look much more realistic. I\\'m going to just skip the story, because it\\'s your standard stalk and kill plot.<br /><br />The next gore scene is something to behold, as the boyfriend from the first killing is taken to a cave like location (TCM-2 stuff), and bound to a table. This geek then cuts all of his limbs off (off camera, with a cue to insert a scene), and then we see his torso on a barbecue pit, turning slowly over a fire, and the torso has a hard-on (if you can believe that). Yes, very bad taste, gross, gruesome, you find the right word, and it will probably fit too.<br /><br />Then later Jenna Jameson, her beautiful body and all, is cut from neck to crotch, and all her entrails are pulled out in graphic glee, and her blood drains into a pot. Yummy, a real turn on huh?<br /><br />But the best gore scene happens inside the house, and I have to admit, this is one of the best gore scenes I have seen. This guy (doesn\\'t matter who) is caught from behind from a geek, and cut open at the ass hole. The geek then puts his hands in and rips out all the guys entrails, intestines, and what the hell ever else there is, right from his asshole. This goes on FOREVER, as the guy is screaming and more and more innards are pulled out laying all over the bathroom floor. This is so extreme, so over the top, that I found myself laughing all to hell. Obviously, you will NEVER EVER see this scene on a proper DVD, IMO, along with most of the other really extreme gore scenes.<br /><br />So, what to think of all of this. Well, first of all, even though I doubt this movie would ever be released in this totally uncut presentation, it makes this \"Rough Cut\" a rare jewel for gorehounds. Yes, it\\'s a little difficult at first, with no soundtrack, a few scenes to still be inserted, and credits that have missing names all over the place. But that\\'s what makes this so unique, and I wouldn\\'t trade it for anything right now. Extreme gore, yes yes, extreme extreme gore. This makes \"Haute Tension\" look like a Disney movie.'\n",
            " 'In this forgettable trifle, the 40-ish Norma Shearer plays a fluttery, girlish socialite in Monte Carlo, caught in a tussle between George Sanders and Robert Taylor. It would be tempting to blame this movie\\'s failure on the dull, talky script, or director George Cukor, who never seems interested in livening up the film\\'s generally comatose state. Mostly, though, it\\'s the fault of Shearer herself, who desperately wanted to keep playing \"young\" parts as long as she could get away with it. Inadvertently, this makes \"Her Cardboard Lover\" a bizarre monument to an aging woman\\'s vanity.'\n",
            " 'Peter O\\'Toole is a treat to watch in roles where the lines he speaks are good and offer a chance for him to swagger in drunken stupor. The lovely Susannah York provides a good foil for O\\'Toole\\'s dramatic presence.<br /><br />The film alludes to incest--without a single explicit scene--but it is able to entertain the viewer in its raucous social commentary. Though this is not major film by any reckoning, it will be remembered for its entertaining performances. <br /><br />Even York, signing the papers at the end, is a treat to watch, exuding tragedy silently. The possible weakness here is Thompson\\'s laid-back direction. But the film floats because of the actors and the script.<br /><br />I saw the film twice over a period of 20 years--on both occasions with the name \"Brotherly love\". \"Country dance\" is a rather farcical and inappropriate title for this movie, wherever it was released as such.'\n",
            " \"This is one of the greatest sports movies ever made by Hollywood. What a wonderful story about one of the great sports figures of American history. What makes the story of James J. Corbett especially interesting is that Mr. Corbett introduced the style of boxing that continues to this day. In that respect James J. Corbett was truly innovated. But getting back to the movie, all the performances were excellent. Alexis Smith was beautiful. Indeed, she looked like Nicole Kidman. And although it's a period piece, the story withstands the test of time; it has not gone stale. Ward Bond's portrayal of John L. Sullivan has to be one of the great portrayals of an actual sports figure in the history of movies and the boxing scenes are realistic, well-staged and highly effective. That coupled with a great script makes this movie a must.\"\n",
            " \"First of all this movie is not a comedy; unless you really force yourself you can hardly laugh. Secondly, the movie is slow and boring. The acting is not bad but not special. There is a Lucky Luke comic about two families (one with big noses and one with big ears) fighting each other in a small town... you will laugh much more if you read this instead of wasting your time with this movie. Religions and dogmas are not the best source to make a good comedy and this movie does nothing more than confirm this rule. There is a similar subject comedy '' The home teachers'' ; this had some good moments. My final comment is: do not waste your time and money to watch this uninspired and boring film.\"\n",
            " \"Without a doubt this is one of the worst films I've ever wasted money on! The plot is, erm sorry, did I say there was a plot? The scariest moment was when..., nope can't think of one! The best special effect that had me hiding under the bed covers was..., nope can't think of one for that either. You knew who the killer was right from the start. There was nothing scary about the whole movie, in fact the only two vaguely interesting bits were when you saw the kid sister, Misty, in the shower and when you saw Nurse Toppan take her top off. This film should only be watched to get an idea of how NOT to make a horror movie!!!\"\n",
            " \"'Deliverance' is a brilliant condensed epic of a group of thoroughly modern men who embark on a canoe trip to briefly commune with nature, and instead have to fight for their sanity, their lives, and perhaps even their souls. The film has aged well. Despite being made in the early Seventies, it certainly doesn't look particularly dated. It still possesses a visceral punch and iconic status as a dramatic post-'Death of the Sixties' philosophical-and-cultural shock vehicle. There are very few films with similar conceits that can compare favourably to it, although the legendary Sam Peckinpah's stuff would have to be up there. Yes, there has been considerable debate and discussion about the film's most confronting scene (which I won't expand upon here) - and undoubtedly one of the most confronting scenes in the entire history of the cinematic medium - but what surprises about this film is how achingly beautiful it is at times. This seems to be generally overlooked (yet in retrospect quite understandably so). The cinematography that captures the essence of the vanishing, fragile river wilderness is often absolutely stunning, and it counterbalances the film as, in a moment of brief madness, we the viewers - along with the characters themselves - are plunged into unrelenting nightmare. 'Deliverance's narrative is fittingly lean and sinewy, and it is surprising how quickly events unfold from point of establishment, through to crisis, and aftermath. It all takes place very quickly, which lends a sense of very real urgency to the film. The setting is established effectively through the opening credits. The characters are all well-drawn despite limited time spent on back story. We know just enough about them to know them for the kind of man they are, like them and ultimately fear for them when all goes to hell. The conflict and violence within the movie seems to erupt out of nowhere, with a frightening lack of logic. This is author James Dickey's theme - that any prevailing romanticism about the nature of Man's perceived inherent 'goodness' can only wilt and die when his barely suppressed animal instincts come to the fore. There are no demons or bogeymen here. The predatory hillbillies - as the film's central villains - are merely crude, terrifyingly amoral cousins of our protagonists. They shock because their evil is petty and tangible. The film has no peripheral characters. All reflect something about the weaknesses and uncertainties of urbanised Homo Sapiens in the latter 20th century, and all are very real and recognisable. Burt Reynolds is wonderful in this movie as the gung-ho and almost fatally over-confident Survivalist, Lewis, and it is a shame to think that he really couldn't recapture his brief moment of dramatic glory throughout the rest of his still sputtering up-and-down career ('Boogie Nights' excluded, perhaps). Trust me, if your are not a Reynolds fan, you WILL be impressed with his performance here. John Voight is his usual effortlessly accomplished self, and Ned Beatty and Ronny Cox both make significant contributions. This is simply a great quartet of actors. To conclude, I must speculate as to if and when 'Deliverance' author James Dickey's 'To the White Sea' will be made. For those that enjoyed (?) this film, TTWS is a similarly harrowing tale of an American Air Force pilot's struggle for survival after being shot down over the Japanese mainland during WW2. It's more of the typically bleak existentialism and primordial savagery that is Dickey's trademark, but it has all the makings of a truly spectacular, poetic cinematic experience. There was the suggestion a few years ago that the Coen brothers might be producing it, but that eventually came to nothing. Being an avid Coen-o-phile it disappoints me to think what might have been had they gotten the green light on TTWS, rather than their last couple of relatively undistinguished efforts. Returning to 'Deliverance', it's impossible to imagine a movie of such honest, unnerving brutality being made in these times, and that is pretty shameful. We, the cinema-going public, are all the poorer for this.\"\n",
            " \"The arrival of White Men in Arctic Canada challenges the freedom of a fearless ESKIMO hunter.<br /><br />W. S. Van Dyke, MGM's peripatetic director, was responsible for this fascinating look at life in the Arctic among the Inuit. His production was on location filming from April 1932 until November 1933 (although some annoying rear projection effects show that some of the shooting took place back at the Studio). While considered a documentary at the time, we would likely term it a 'docudrama' as it is scripted with an intriguing plot & storyline.<br /><br />The film shows the daily life of the Eskimo, both Winter & Summer, and in fact starts in the warmer time of the year without any snow or ice in sight. The constant striving for food is depicted, and the viewer gets to watch the exciting hunts for walrus, polar bear, whale & caribou. The native language is used throughout, with the use of title cards; the only English is spoken by the fishermen & Mounties encountered by the Eskimo. In fact, it is the arrival of White Men, both good & bad, and the change they make on Eskimo society, which is a major element in the narrative.<br /><br />This Pre-Code film deals in a refreshingly frank manner with the Eskimo moral code, particularly with their practice of wife-sharing, which was an important and completely innocent part of their culture. In fact, the entire film can be appreciated as a valuable look at a way of life which was rapidly disappearing even in the early 1930's.<br /><br />None of the cast receives screen credit, which is a shame as there are some notable performances. Foremost among them is that of Ray Wise, playing the leading role of Mala the Eskimo. Wise (1906-1952) was an Alaskan Native of Inuit ancestry and is absolutely splendid and perfectly believable in what was a very demanding part. As handsome as any Hollywood star, he would continue acting, using the name of Ray Mala, in a sporadic film career, often in tiny unbilled roles.<br /><br />Lovely Japanese-Hawaiian actress Lotus Long plays Mala's loyal second wife; the names of the fine actresses playing his other two wives are now obscure. Director Woody Van Dyke steps in front of the cameras as a strict North West Mounted Police inspector. The two decent-hearted Mounties who must deliver Mala to Canadian justice are played by Joe Sawyer & Edgar Dearing, both longtime movie character actors. Danish author Peter Freuchen, upon whose books the film was based, has a short vivid role of an evil wooden-legged sea captain who unwisely rouses Mala's icy wrath.\"\n",
            " 'Curiously, Season 6 of the Columbo series contained only three episodes and there is very little evidence of quality in at least two of the scripts, based on this outing for the \"man-in-the-mac\" and also \"Fade into Murder\".<br /><br />Furthermore, it is not a coincidence that Peter S. Feibleman penned both the aforementioned scripts (incidentally he plays the part of the murdered security guard here).<br /><br />This adventure is very rarely compelling and many of the performers just look disinterested with the material. The story is rather weakly developed with some protracted periods of boring conversation.<br /><br />Columbo is also shadowed by a colleague here(similar to \"Last Salute to the Commodore\") but the entertainment value is minimal. To add to this, Celeste\\'s Holm characterisation, which is intended to provide comedy, induces embarrassment rather than laughs.<br /><br />The script wavers off to deal with the family history and the murderess does enough to gift Columbo the case, though there is never a credible discussion relating to the motives of her crime.<br /><br />Ironically, what turns out to be, arguably, Columbo\\'s worst adventure produces the funniest moment in the series. He quizzes a male hairdresser and has a haircut/manicure at the same time. The next 5 minutes are hilarious - it\\'s just that Columbo\\'s hair is so perfectly groomed, then he can\\'t afford to pay the bill and then, when he makes enquiries at a jewellers he keeps glancing in the mirror to admire his hairstyle!<br /><br />Sadly, this is the only decent moment from a script that looks like it has been cobbled together in ten minutes. <br /><br />For Columbo completionists only.'\n",
            " 'The year 2005 saw no fewer than 3 filmed productions of H. G. Wells\\' great novel, \"War of the Worlds\". This is perhaps the least well-known and very probably the best of them. No other version of WotW has ever attempted not only to present the story very much as Wells wrote it, but also to create the atmosphere of the time in which it was supposed to take place: the last year of the 19th Century, 1900 \\x85 using Wells\\' original setting, in and near Woking, England.<br /><br />IMDb seems unfriendly to what they regard as \"spoilers\". That might apply with some films, where the ending might actually be a surprise, but with regard to one of the most famous novels in the world, it seems positively silly. I have no sympathy for people who have neglected to read one of the seminal works in English literature, so let\\'s get right to the chase. The aliens are destroyed through catching an Earth disease, against which they have no immunity. If that\\'s a spoiler, so be it; after a book and 3 other films (including the 1953 classic), you ought to know how this ends.<br /><br />This film, which follows Wells\\' plot in the main, is also very cleverly presented \\x96 in a way that might put many viewers off due to their ignorance of late 19th/early 20th Century photography. Although filmed in a widescreen aspect, the film goes to some lengths to give an impression of contemporaneity. The general coloration of skin and clothes display a sepia tint often found in old photographs (rather than black). Colors are often reminiscent of hand-tinting. At other times, colors are washed out. These variations are typical of early films, which didn\\'t use standardized celluloid stock and therefore presented a good many changes in print quality, even going from black/white to sepia/white to blue/white to reddish/white and so on \\x96 as you\\'ll see on occasion here. The special effects are deliberately retrograde, of a sort seen even as late as the 1920s \\x96 and yet the Martians and their machines are very much as Wells described them and have a more nearly realistic \"feel\". Some of effects are really awkward \\x96 such as the destruction of Big Ben. The acting is often more in the style of that period than ours. Some aspects of Victorian dress may appear odd, particularly the use of pomade or brilliantine on head and facial hair.<br /><br />This film is the only one that follows with some closeness Wells\\' original narrative \\x96 as has been noted. Viewers may find it informative to note plot details that appear here that are occasionally retained in other versions of the story. Wells\\' description of the Martians \\x96 a giant head mounted on numerous tentacles \\x96 is effectively portrayed. When the Martian machines appear, about an hour into the film, they too give a good impression of how Wells described them. Both Wells and this film do an excellent job of portraying the progress of the Martians from the limited perspective (primarily) of rural England \\x96 plus a few scenes in London (involving the Narrator\\'s brother). The director is unable to resist showing the destruction of a major landmark (Big Ben), but at least doesn\\'t dwell unduly on the devastation of London.<br /><br />The victory of the Martians is hardly a surprise, despite the destruction by cannon of some of their machines. The Narrator, traveling about to seek escape, sees much of what Wells terms \"the rout of Mankind\". He encounters a curate endowed with the Victorian affliction of a much too precious and nervous personality. They eventually find themselves on the very edge of a Martian nest, where they discover an awful fact: the Martians are shown to be vampires who consume their prey alive in a very effective scene. Wells adds that after eating they set up \"a prolonged and cheerful hooting\". The Narrator finally is obliged to beat senseless the increasingly hysterical curate \\x96 who revives just as the Martians drag him off to the larder (cheers from the gallery; British curates are so often utterly insufferable).<br /><br />This film lasts almost 3 hours, going through Wells\\' story in welcome detail. It\\'s about time the author got his due \\x96 in a compelling presentation that builds in dramatic impact. A word about the acting: Don\\'t expect award-winning performances. They\\'re not bad, however, the actors are earnest and they grow on you. Most of them, however, have had very abbreviated film careers, often only in this film. The Narrator is played by hunky Anthony Piana, in his 2nd film. The Curate is John Kaufman \\x96 also in his 2nd film as an actor but who has had more experience directing. The Brother (\"Henderson\") is played with some conviction by W. Bernard Bauman in his first film. The Artilleryman, the only other sizable part, is played by James Lathrop in his first film.<br /><br />This is overall a splendid film, portraying for the first time the War of the Worlds as Wells wrote it. Despite its slight defects, it is far and away better than any of its hyped-up competitors. If you want to see H. G. Wells\\' War of the Worlds \\x96 and not some wholly distorted version of it \\x96 see this film!']\n",
            "10\n"
          ]
        }
      ],
      "source": [
        "testing_array = df['Review'].values\n",
        "print(testing_array)\n",
        "print(len(testing_array))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-MuV0KVdAnnQ"
      },
      "source": [
        "###  **Step 2:** Prompt the text generative LLM - using the prompt given below\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "g4kZ3EFI-CbW"
      },
      "source": [
        "**Query the text generating llm with the following prompt:** (copy the document as mentionned: PASTE_DOCUMENTS_HERE)\n",
        "\n",
        "```\n",
        "Please classify the following 10 sentences: positive, negative or neutral. Here are the sentences:\n",
        "```\n",
        "```\n",
        "PASTE_SENTENCES_HERE. please return the answers as an array\n",
        "```"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xG5uVf6IAyIb"
      },
      "source": [
        "### **Step 3:** Computing and calculating the scores & download results\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "Q2vDiwrN9_L1"
      },
      "outputs": [],
      "source": [
        "# Add the result\n",
        "predicted_labels = ['Positive', 'Negative', 'Neutral', 'Negative', 'Negative', 'Negative', 'Positive', 'Neutral', 'Negative', 'Positive']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AhYWAJzU90y4",
        "outputId": "73df8113-519b-46dd-8360-6d05e19e75d6"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Total Score: 0.7\n",
            "\n",
            "DataFrame with 10 random reviews:\n"
          ]
        }
      ],
      "source": [
        "df['Predicted_Labels'] = predicted_labels\n",
        "correct_predictions = sum(df['Ground_Truth_Label'] == df['Predicted_Labels'])\n",
        "total_reviews = len(df)\n",
        "accuracy = correct_predictions / total_reviews\n",
        "print(\"Total Score:\", accuracy)\n",
        "print(\"\\nDataFrame with 10 random reviews:\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 363
        },
        "id": "rGsZMiiV--oZ",
        "outputId": "4bdba829-9726-4904-c886-2a02dff80b4b"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Unnamed: 0</th>\n",
              "      <th>Review</th>\n",
              "      <th>Ground_Truth_Label</th>\n",
              "      <th>Predicted_Labels</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>Just got through watching this version of \"Sam...</td>\n",
              "      <td>Positive</td>\n",
              "      <td>Positive</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>In this forgettable trifle, the 40-ish Norma S...</td>\n",
              "      <td>Negative</td>\n",
              "      <td>Negative</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2</td>\n",
              "      <td>Peter O'Toole is a treat to watch in roles whe...</td>\n",
              "      <td>Positive</td>\n",
              "      <td>Neutral</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3</td>\n",
              "      <td>This is one of the greatest sports movies ever...</td>\n",
              "      <td>Positive</td>\n",
              "      <td>Negative</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>4</td>\n",
              "      <td>First of all this movie is not a comedy; unles...</td>\n",
              "      <td>Negative</td>\n",
              "      <td>Negative</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>5</td>\n",
              "      <td>Without a doubt this is one of the worst films...</td>\n",
              "      <td>Negative</td>\n",
              "      <td>Negative</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>6</td>\n",
              "      <td>'Deliverance' is a brilliant condensed epic of...</td>\n",
              "      <td>Positive</td>\n",
              "      <td>Positive</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>7</td>\n",
              "      <td>The arrival of White Men in Arctic Canada chal...</td>\n",
              "      <td>Positive</td>\n",
              "      <td>Neutral</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>8</td>\n",
              "      <td>Curiously, Season 6 of the Columbo series cont...</td>\n",
              "      <td>Negative</td>\n",
              "      <td>Negative</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>9</td>\n",
              "      <td>The year 2005 saw no fewer than 3 filmed produ...</td>\n",
              "      <td>Positive</td>\n",
              "      <td>Positive</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   Unnamed: 0                                             Review  \\\n",
              "0           0  Just got through watching this version of \"Sam...   \n",
              "1           1  In this forgettable trifle, the 40-ish Norma S...   \n",
              "2           2  Peter O'Toole is a treat to watch in roles whe...   \n",
              "3           3  This is one of the greatest sports movies ever...   \n",
              "4           4  First of all this movie is not a comedy; unles...   \n",
              "5           5  Without a doubt this is one of the worst films...   \n",
              "6           6  'Deliverance' is a brilliant condensed epic of...   \n",
              "7           7  The arrival of White Men in Arctic Canada chal...   \n",
              "8           8  Curiously, Season 6 of the Columbo series cont...   \n",
              "9           9  The year 2005 saw no fewer than 3 filmed produ...   \n",
              "\n",
              "  Ground_Truth_Label Predicted_Labels  \n",
              "0           Positive         Positive  \n",
              "1           Negative         Negative  \n",
              "2           Positive          Neutral  \n",
              "3           Positive         Negative  \n",
              "4           Negative         Negative  \n",
              "5           Negative         Negative  \n",
              "6           Positive         Positive  \n",
              "7           Positive          Neutral  \n",
              "8           Negative         Negative  \n",
              "9           Positive         Positive  "
            ]
          },
          "execution_count": 16,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "CBypDP6z_dqU"
      },
      "outputs": [],
      "source": [
        "model_name = \"Chat GPT\"\n",
        "output_filename = \"chat_gpt_sentiment.csv\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vlyYgymT_CDg",
        "outputId": "8e82887e-501f-4b03-ea43-95c9a405d08a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "  model_name  accuracy\n",
            "0   Chat GPT       0.7\n"
          ]
        }
      ],
      "source": [
        "new_data = {\n",
        "    'model_name': model_name,\n",
        "    'accuracy': [accuracy]\n",
        "}\n",
        "new_df = pd.DataFrame(new_data)\n",
        "new_df.to_csv(output_filename, index=False)\n",
        "print(new_df)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1Pxg7y-usD-b"
      },
      "source": [
        "### **Step 4:** Compress all in 1 function"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "_imQdyYCsEpx"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "\n",
        "def calculate_and_export_sent_analysis(model_name, opt_result):\n",
        "    df = pd.read_csv(\"./content/dataset_sample_movie_reviews.csv\") # Adjust path if necessary\n",
        "    # Convert both predicted and ground truth labels to lowercase\n",
        "    predicted_labels = [label.lower() for label in opt_result]\n",
        "    df['Predicted_Labels'] = predicted_labels\n",
        "    df['Ground_Truth_Label'] = df['Ground_Truth_Label'].str.lower()\n",
        "    # Count correct predictions\n",
        "    correct_predictions = sum(df['Ground_Truth_Label'] == df['Predicted_Labels'])\n",
        "    total_reviews = len(df)\n",
        "    accuracy = correct_predictions / total_reviews\n",
        "    # Create DataFrame with accuracy and model name\n",
        "    new_data = {\n",
        "        'model_name': model_name,\n",
        "        'accuracy': [accuracy]\n",
        "    }\n",
        "    new_df = pd.DataFrame(new_data)\n",
        "    # Export to CSV\n",
        "    output_filename = f\"./results/{model_name}.csv\"\n",
        "    new_df.to_csv(output_filename, index=False)\n",
        "\n",
        "    return new_df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 363
        },
        "id": "mAhXJ5AWtOVY",
        "outputId": "764833ed-d492-474b-f850-2898ba1ee33f"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Review</th>\n",
              "      <th>Ground_Truth_Label</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>I wanted to like this movie. But it falls apar...</td>\n",
              "      <td>Negative</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Even if it were remotely funny, this mouldy wa...</td>\n",
              "      <td>Negative</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>This is an excellent film and one should not b...</td>\n",
              "      <td>Positive</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Despite having known people who are either gre...</td>\n",
              "      <td>Negative</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>One word: suPURRRRb! I don't think I have see ...</td>\n",
              "      <td>Positive</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>The early career of Abe Lincoln is beautifully...</td>\n",
              "      <td>Positive</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>I bought this at tower records after seeing th...</td>\n",
              "      <td>Negative</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>Steven Spielberg produced, wrote, came up with...</td>\n",
              "      <td>Positive</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>When I took my seat in the cinema I was in a c...</td>\n",
              "      <td>Positive</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>I wonder how the actors acted in this movie. A...</td>\n",
              "      <td>Negative</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                              Review Ground_Truth_Label\n",
              "0  I wanted to like this movie. But it falls apar...           Negative\n",
              "1  Even if it were remotely funny, this mouldy wa...           Negative\n",
              "2  This is an excellent film and one should not b...           Positive\n",
              "3  Despite having known people who are either gre...           Negative\n",
              "4  One word: suPURRRRb! I don't think I have see ...           Positive\n",
              "5  The early career of Abe Lincoln is beautifully...           Positive\n",
              "6  I bought this at tower records after seeing th...           Negative\n",
              "7  Steven Spielberg produced, wrote, came up with...           Positive\n",
              "8  When I took my seat in the cinema I was in a c...           Positive\n",
              "9  I wonder how the actors acted in this movie. A...           Negative"
            ]
          },
          "execution_count": 23,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "model_name = \"chat_gpt\"\n",
        "# Generate the results by copy pasting the following prompt:\n",
        "df = pd.read_csv(\"./content/dataset_sample_movie_reviews.csv\") # Adjust path if necessary\n",
        "df[[\"Review\",'Ground_Truth_Label']]\n",
        "# Click on the icon next to *Review* (convert this dataframe to an interactive table) - then select (right) copy table and select JSON and copy - paste the result in the cell below  replacing **PASTE_DOCUMENTS_HERE**\n",
        "# Then copy the entire cell and prompt the LLM"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "id": "sVTc_glatd_q"
      },
      "outputs": [],
      "source": [
        "#Please classify the following 10 sentences: positive or negative. Here are the sentences please provide an array for answer i.e: predicted_labels = ['positive','negative',...]:: PASTE_SENTENCES_HERE. please return the answers as an array"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "id": "Ck-_3n1RuODO"
      },
      "outputs": [],
      "source": [
        "# Example usage:\n",
        "predicted_labels = ['negative', 'negative', 'positive', 'negative', 'positive', 'positive', 'negative', 'negative', 'positive', 'negative']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 80
        },
        "id": "6GVUU6fuuXWV",
        "outputId": "ed0ab2e8-0851-486c-ee31-34c108e3296f"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>model_name</th>\n",
              "      <th>accuracy</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>chat_gpt</td>\n",
              "      <td>0.9</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "  model_name  accuracy\n",
              "0   chat_gpt       0.9"
            ]
          },
          "execution_count": 27,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Example usage:\n",
        "calculate_and_export_sent_analysis(model_name, predicted_labels)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 80
        },
        "id": "L1ukiN3nuco2",
        "outputId": "e068aeb1-fc7a-4792-9779-86678bfd00c4"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>model_name</th>\n",
              "      <th>accuracy</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>chat_gpt</td>\n",
              "      <td>0.9</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "  model_name  accuracy\n",
              "0   chat_gpt       0.9"
            ]
          },
          "execution_count": 30,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df = pd.read_csv(f\"./results/{model_name}.csv\")  # delete . if on colab\n",
        "df"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
